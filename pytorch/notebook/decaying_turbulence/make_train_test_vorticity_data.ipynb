{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcfafe-6882-4552-be3c-94bce4016b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac270c-d0e7-43c1-85e0-040f436bc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "log_handler = StreamHandler(sys.stdout)\n",
    "logger.addHandler(log_handler)\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57891ef-4532-4732-8a96-3e6505611eae",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3e96c-b93a-4171-89bc-22cf2887ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "ROOT_DIR = \"/workspace\"\n",
    "\n",
    "sys.path.append(f\"{ROOT_DIR}/pytorch/src\")\n",
    "from io_fortran_data import read_vortex_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28378d58-44c4-4821-b03a-e3bf87f1fd89",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85c154-faee-4d16-a966-109df1551f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = f\"{ROOT_DIR}/data/fortran/decaying_turbulence/train\"\n",
    "TEST_DATA_DIR = f\"{ROOT_DIR}/data/fortran/decaying_turbulence/test\"\n",
    "OUTPUT_DIR = f\"{ROOT_DIR}/data/pytorch/decaying_turbulence/DL_data/vorticity\"\n",
    "\n",
    "TSTEP_START = 110  # inclusive\n",
    "TSTEP_END = 200  # inclusive\n",
    "TSTEP_INTERVAL = 10\n",
    "DT = 0.01\n",
    "\n",
    "K_MAX = 42\n",
    "NX = 128\n",
    "NY = NX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e073af-b98a-4c05-9249-b9b64d3178c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4678af9-aba2-4943-bd8c-66b675fc6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 2 * np.pi, NX)\n",
    "ys = np.linspace(0, 2 * np.pi, NY)\n",
    "X, Y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "\n",
    "for kind, dir_path in zip([\"train\", \"test\"], [TRAIN_DATA_DIR, TEST_DATA_DIR]):\n",
    "    display(HTML(f\"<h2>{kind}</h2>\"))\n",
    "    for file_path in glob(f\"{dir_path}/T{K_MAX}*.dat\")[:2]:\n",
    "        vortex_field = read_vortex_file(file_path, NX, NY)\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "        for it, (Z, ax) in enumerate(\n",
    "            zip(\n",
    "                vortex_field[TSTEP_START : TSTEP_END + TSTEP_INTERVAL : TSTEP_INTERVAL, :, :],\n",
    "                np.ravel(axes),\n",
    "            )\n",
    "        ):\n",
    "            vmin, vmax = np.min(Z), np.max(Z)\n",
    "            vmin, vmax = -max([np.abs(vmin), np.abs(vmax)]), max([np.abs(vmin), np.abs(vmax)])\n",
    "            levels = np.linspace(vmin, vmax, 21)\n",
    "\n",
    "            ax.axis(\"off\")\n",
    "            ax.contourf(X, Y, Z, cmap=\"coolwarm\", levels=levels)\n",
    "            t = DT * (TSTEP_START + it * TSTEP_INTERVAL)\n",
    "            ax.set_title(f\"t = {t:.2f}\\nabs max = {vmax:.0f}\")\n",
    "            ax.set_aspect(\"equal\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ef632-0575-425f-8dda-593687e38e02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make data for DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d58af1-e9db-48ae-9e7b-03b570737db8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeee4c7-1b0d-425a-b3fb-7951fc480efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_paths = sorted(glob(f\"{TRAIN_DATA_DIR}/T{K_MAX}*.dat\"))\n",
    "print(f\"Total file num = {len(all_file_paths)}\")\n",
    "\n",
    "train_file_paths, valid_file_paths = train_test_split(all_file_paths, test_size=0.3, shuffle=False)\n",
    "\n",
    "for kind, paths in zip([\"train\", \"valid\"], [train_file_paths, valid_file_paths]):\n",
    "    print(f\"kind = {kind}, len(paths) = {len(paths)}\")\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{kind}\", exist_ok=False)\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        Zs = read_vortex_file(path, NX, NY)\n",
    "        for it in range(TSTEP_START, TSTEP_END + TSTEP_INTERVAL, TSTEP_INTERVAL):\n",
    "            # e.g., T85_seed12382771132014.dat --> seed12382771132014\n",
    "            seed_info = os.path.basename(path).split(\"_\")[-1].split(\".\")[0]\n",
    "            output_path = f\"{OUTPUT_DIR}/{kind}/T{K_MAX}_{seed_info}_it{it:04}.npy\"\n",
    "            np.save(output_path, Zs[it, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f2c5a-8c29-4e3c-83c4-c0695e675882",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ebfec-0154-40d0-856c-562db69f6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = \"test\"\n",
    "paths = sorted(glob(f\"{TEST_DATA_DIR}/T{K_MAX}*.dat\"))\n",
    "\n",
    "print(f\"kind = {kind}, len(paths) = {len(paths)}\")\n",
    "os.makedirs(f\"{OUTPUT_DIR}/{kind}\", exist_ok=False)\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    Zs = read_vortex_file(path, NX, NY)\n",
    "    for it in range(TSTEP_START, TSTEP_END + TSTEP_INTERVAL, TSTEP_INTERVAL):\n",
    "        # e.g., T85_seed12382771132014.dat --> seed12382771132014\n",
    "        seed_info = os.path.basename(path).split(\"_\")[-1].split(\".\")[0]\n",
    "        output_path = f\"{OUTPUT_DIR}/{kind}/T{K_MAX}_{seed_info}_it{it:04}.npy\"\n",
    "        np.save(output_path, Zs[it, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103645e7-d063-4c86-b61c-0c694ea35d0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check train, valid, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1627f-1523-46ca-acf1-f39dba1836d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 2 * np.pi, NX)\n",
    "ys = np.linspace(0, 2 * np.pi, NY)\n",
    "X, Y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "for kind in [\"train\", \"valid\", \"test\"]:\n",
    "    display(HTML(f\"<h2>{kind}</h2>\"))\n",
    "\n",
    "    dir_path = f\"{OUTPUT_DIR}/{kind}\"\n",
    "    first_path = sorted(glob(f\"{dir_path}/*.npy\"))[0]\n",
    "    seed_info = os.path.basename(first_path).split(\"_\")[1]\n",
    "\n",
    "    assert len(glob(f\"{dir_path}/*{seed_info}*\")) == (TSTEP_END - TSTEP_START) // TSTEP_INTERVAL + 1\n",
    "    paths = sorted(glob(f\"{dir_path}/*{seed_info}*\"))[:10]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "    for path, ax in zip(paths, np.ravel(axes)):\n",
    "        Z = np.load(path)\n",
    "        vmin, vmax = np.min(Z), np.max(Z)\n",
    "        vmin, vmax = -max([np.abs(vmin), np.abs(vmax)]), max([np.abs(vmin), np.abs(vmax)])\n",
    "        levels = np.linspace(vmin, vmax, 21)\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "        ax.contourf(X, Y, Z, cmap=\"coolwarm\", levels=levels)\n",
    "        ax.set_title(f\"{os.path.basename(path).split('_')[-1].split('.')[0]}\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a83bd-b1d5-4020-a500-0be55beba5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = \"valid\"\n",
    "dir_path = f\"{OUTPUT_DIR}/{kind}\"\n",
    "paths = sorted(glob(f\"{dir_path}/*.npy\"))\n",
    "\n",
    "all_zs = []\n",
    "for path in paths:\n",
    "    all_zs.append(np.load(path).flatten())\n",
    "all_zs = np.concatenate(all_zs)\n",
    "len(all_zs) // (NX * NY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb15473-db21-4798-a139-cf19380a35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(all_zs)\n",
    "p25, p75 = np.percentile(all_zs, [25, 75])\n",
    "std = p75 - p25\n",
    "xs = np.linspace(-200, 200, 401)\n",
    "ys = 1 / np.sqrt(2 * np.pi * std ** 2) * np.exp(-0.5 * xs ** 2 / std ** 2)\n",
    "print(std, np.mean(all_zs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a44fd-596f-4083-add4-c1c80fb31ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_zs, bins=400, range=(-200, 200), density=True)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ca8fa-206b-4e24-9d50-ce57fc0a06d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = VortexDatasetForDecayingTurbulence(\n",
    "    data_dir=f\"{OUTPUT_DIR}/valid\",\n",
    "    mean=0.0,\n",
    "    std=16.0,\n",
    "    scale=8,\n",
    "    image_width=None,\n",
    "    image_height=None,\n",
    "    lr_method=\"subsample\",\n",
    "    num_simulations=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2597fa8-95ac-47cb-adad-7a00e97f2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_xs, all_ys = [], []\n",
    "\n",
    "for i, (x, y) in enumerate(iter(datasets)):\n",
    "    all_xs.append(x.numpy().flatten())\n",
    "    all_ys.append(y.numpy().flatten())\n",
    "    if i + 1 <= 5:\n",
    "        print(f\"x size = {x.shape}, y size = {y.shape}\")\n",
    "        vmin, vmax = torch.min(y), torch.max(y)\n",
    "        ax = plt.subplot(121)\n",
    "        ax.imshow(x.numpy().squeeze(), vmin=vmin, vmax=vmax, interpolation=None)\n",
    "        ax = plt.subplot(122)\n",
    "        ax.imshow(y.numpy().squeeze(), vmin=vmin, vmax=vmax, interpolation=None)\n",
    "        plt.show()\n",
    "all_xs, all_ys = np.concatenate(all_xs), np.concatenate(all_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f8e2d-6462-47c4-b993-b34ab79c19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(all_xs, range=(-10, 10), bins=101)\n",
    "plt.show()\n",
    "plt.hist(all_ys, range=(-10, 10), bins=101)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbed08f-aa70-4cea-80b4-4c8e7f26520c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
