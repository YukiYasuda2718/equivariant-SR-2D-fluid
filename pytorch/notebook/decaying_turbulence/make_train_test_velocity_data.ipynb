{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcfafe-6882-4552-be3c-94bce4016b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac270c-d0e7-43c1-85e0-040f436bc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "log_handler = StreamHandler(sys.stdout)\n",
    "logger.addHandler(log_handler)\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57891ef-4532-4732-8a96-3e6505611eae",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3e96c-b93a-4171-89bc-22cf2887ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "ROOT_DIR = \"/workspace\"\n",
    "\n",
    "sys.path.append(f\"{ROOT_DIR}/pytorch/src\")\n",
    "from io_fortran_data import read_vortex_file\n",
    "from np_fft_helper import calc_derivative, calc_velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28378d58-44c4-4821-b03a-e3bf87f1fd89",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b85c154-faee-4d16-a966-109df1551f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = f\"{ROOT_DIR}/data/fortran/decaying_turbulence/train\"\n",
    "TEST_DATA_DIR = f\"{ROOT_DIR}/data/fortran/decaying_turbulence/test\"\n",
    "OUTPUT_DIR = f\"{ROOT_DIR}/data/pytorch/decaying_turbulence/DL_data/velocity\"\n",
    "\n",
    "TSTEP_START = 110  # inclusive\n",
    "TSTEP_END = 200  # inclusive\n",
    "TSTEP_INTERVAL = 10\n",
    "DT = 0.01\n",
    "\n",
    "K_MAX = 42\n",
    "NX = 128\n",
    "NY = NX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916c24c-a5f4-4aeb-890d-e0c7450c91af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e15e5-a78d-4a17-851f-16ae756be332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_velocity_vector(Z: np.ndarray) -> np.ndarray:\n",
    "    U = calc_velocity(Z, is_xcomponent=True)\n",
    "    V = calc_velocity(Z, is_xcomponent=False)\n",
    "    return np.stack([U, V])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111ac3f-d0b1-4ebb-953b-d1e1595e8bcf",
   "metadata": {},
   "source": [
    "# Plot raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4678af9-aba2-4943-bd8c-66b675fc6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 2 * np.pi, NX)\n",
    "ys = np.linspace(0, 2 * np.pi, NY)\n",
    "X, Y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = 2\n",
    "\n",
    "for kind, dir_path in zip([\"train\", \"test\"], [TRAIN_DATA_DIR, TEST_DATA_DIR]):\n",
    "    display(HTML(f\"<h2>{kind}</h2>\"))\n",
    "    for file_path in glob(f\"{dir_path}/T{K_MAX}*.dat\")[:1]:\n",
    "        vortex_field = read_vortex_file(file_path, NX, NY)\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "        for it, (Z, ax) in enumerate(\n",
    "            zip(\n",
    "                vortex_field[TSTEP_START : TSTEP_END + TSTEP_INTERVAL : TSTEP_INTERVAL, :, :],\n",
    "                np.ravel(axes),\n",
    "            )\n",
    "        ):\n",
    "            velocity = calc_velocity_vector(Z)\n",
    "            U, V = velocity[0], velocity[1]\n",
    "            vmin, vmax = np.min(Z), np.max(Z)\n",
    "            vmin, vmax = -max([np.abs(vmin), np.abs(vmax)]), max([np.abs(vmin), np.abs(vmax)])\n",
    "            levels = np.linspace(vmin, vmax, 21)\n",
    "\n",
    "            ax.axis(\"off\")\n",
    "            ax.contourf(X, Y, Z, cmap=\"coolwarm\", levels=levels, alpha=0.2)\n",
    "\n",
    "            interval = 8\n",
    "            ax.quiver(\n",
    "                X[::interval, ::interval],\n",
    "                Y[::interval, ::interval],\n",
    "                U[::interval, ::interval],\n",
    "                V[::interval, ::interval],\n",
    "                units=\"xy\",\n",
    "                scale_units=\"xy\",\n",
    "                angles=\"xy\",\n",
    "            )\n",
    "\n",
    "            t = DT * (TSTEP_START + it * TSTEP_INTERVAL)\n",
    "            ax.set_title(f\"t = {t:.2f}\\nabs max = {vmax:.0f}\")\n",
    "            ax.set_aspect(\"equal\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ef632-0575-425f-8dda-593687e38e02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make data for DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d58af1-e9db-48ae-9e7b-03b570737db8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeee4c7-1b0d-425a-b3fb-7951fc480efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_paths = sorted(glob(f\"{TRAIN_DATA_DIR}/T{K_MAX}*.dat\"))\n",
    "print(f\"Total file num = {len(all_file_paths)}\")\n",
    "\n",
    "train_file_paths, valid_file_paths = train_test_split(all_file_paths, test_size=0.3, shuffle=False)\n",
    "\n",
    "for kind, paths in zip([\"train\", \"valid\"], [train_file_paths, valid_file_paths]):\n",
    "    print(f\"kind = {kind}, len(paths) = {len(paths)}\")\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{kind}\", exist_ok=False)\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        Zs = read_vortex_file(path, NX, NY)\n",
    "        for it in range(TSTEP_START, TSTEP_END + TSTEP_INTERVAL, TSTEP_INTERVAL):\n",
    "            # e.g., T85_seed12382771132014.dat --> seed12382771132014\n",
    "            seed_info = os.path.basename(path).split(\"_\")[-1].split(\".\")[0]\n",
    "            output_path = f\"{OUTPUT_DIR}/{kind}/T{K_MAX}_{seed_info}_it{it:04}.npy\"\n",
    "            velocity = calc_velocity_vector(Zs[it, :, :])\n",
    "            np.save(output_path, velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f2c5a-8c29-4e3c-83c4-c0695e675882",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ebfec-0154-40d0-856c-562db69f6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "kind = \"test\"\n",
    "paths = sorted(glob(f\"{TEST_DATA_DIR}/T{K_MAX}*.dat\"))\n",
    "\n",
    "print(f\"kind = {kind}, len(paths) = {len(paths)}\")\n",
    "os.makedirs(f\"{OUTPUT_DIR}/{kind}\", exist_ok=False)\n",
    "\n",
    "for path in tqdm(paths):\n",
    "    Zs = read_vortex_file(path, NX, NY)\n",
    "    for it in range(TSTEP_START, TSTEP_END + TSTEP_INTERVAL, TSTEP_INTERVAL):\n",
    "        # e.g., T85_seed12382771132014.dat --> seed12382771132014\n",
    "        seed_info = os.path.basename(path).split(\"_\")[-1].split(\".\")[0]\n",
    "        output_path = f\"{OUTPUT_DIR}/{kind}/T{K_MAX}_{seed_info}_it{it:04}.npy\"\n",
    "        velocity = calc_velocity_vector(Zs[it, :, :])\n",
    "        np.save(output_path, velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103645e7-d063-4c86-b61c-0c694ea35d0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check train, valid, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1627f-1523-46ca-acf1-f39dba1836d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 2 * np.pi, NX)\n",
    "ys = np.linspace(0, 2 * np.pi, NY)\n",
    "X, Y = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "for kind in [\"train\", \"valid\", \"test\"]:\n",
    "    display(HTML(f\"<h2>{kind}</h2>\"))\n",
    "\n",
    "    dir_path = f\"{OUTPUT_DIR}/{kind}\"\n",
    "    first_path = sorted(glob(f\"{dir_path}/*.npy\"))[0]\n",
    "    seed_info = os.path.basename(first_path).split(\"_\")[1]\n",
    "\n",
    "    assert len(glob(f\"{dir_path}/*{seed_info}*\")) == (TSTEP_END - TSTEP_START) // TSTEP_INTERVAL + 1\n",
    "    paths = sorted(glob(f\"{dir_path}/*{seed_info}*\"))[:10]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 5, sharex=True, sharey=True, figsize=[10, 4])\n",
    "\n",
    "    for path, ax in zip(paths, np.ravel(axes)):\n",
    "        velocity = np.load(path)\n",
    "        U, V = velocity[0, :, :], velocity[1, :, :]\n",
    "        Z = calc_derivative(V, is_x=True) - calc_derivative(U, is_x=False)\n",
    "\n",
    "        vmin, vmax = np.min(Z), np.max(Z)\n",
    "        vmin, vmax = -max([np.abs(vmin), np.abs(vmax)]), max([np.abs(vmin), np.abs(vmax)])\n",
    "        levels = np.linspace(vmin, vmax, 21)\n",
    "        ax.axis(\"off\")\n",
    "        ax.contourf(X, Y, Z, cmap=\"coolwarm\", levels=levels, alpha=0.5)\n",
    "\n",
    "        interval = 8\n",
    "        ax.quiver(\n",
    "            X[::interval, ::interval],\n",
    "            Y[::interval, ::interval],\n",
    "            U[::interval, ::interval],\n",
    "            V[::interval, ::interval],\n",
    "            units=\"xy\",\n",
    "            scale_units=\"xy\",\n",
    "            angles=\"xy\",\n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"{os.path.basename(path).split('_')[-1].split('.')[0]}\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2597fa8-95ac-47cb-adad-7a00e97f2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(2):\n",
    "    all_xs, all_ys = [], []\n",
    "    for i, (xs, ys) in enumerate(iter(datasets)):\n",
    "        x, y = xs[j, :, :], ys[j, :, :]\n",
    "        all_xs.append(x.numpy().flatten())\n",
    "        all_ys.append(y.numpy().flatten())\n",
    "        if i + 1 <= 2:\n",
    "            print(f\"x size = {x.shape}, y size = {y.shape}\")\n",
    "            vmin, vmax = torch.min(y), torch.max(y)\n",
    "            ax = plt.subplot(121)\n",
    "            ax.imshow(x.numpy().squeeze(), vmin=vmin, vmax=vmax, interpolation=None)\n",
    "            ax = plt.subplot(122)\n",
    "            ax.imshow(y.numpy().squeeze(), vmin=vmin, vmax=vmax, interpolation=None)\n",
    "            plt.show()\n",
    "    all_xs, all_ys = np.concatenate(all_xs), np.concatenate(all_ys)\n",
    "    plt.hist(all_xs, range=(-10, 10), bins=101)\n",
    "    plt.show()\n",
    "    plt.hist(all_ys, range=(-10, 10), bins=101)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
